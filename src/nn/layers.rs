pub mod dense;
pub mod input;
pub mod convolution2d;
pub mod max_pooling_layer;

extern crate rand;
use crate::geoalg::f32_math::matrix::*;

/// Learning rate to affect how layers apply back-propagation.
pub fn learning_rate() -> f32 {
    0.01
}

pub trait Propagates {
    /// Generates output to be fed into the next layer.
    /// The outputs should be saved for backward to work, but only when training.
    /// Since forward can be useful on its own and doesn't always need to backpropagate, we leave the saving of the output to the implementer.
    fn forward(&mut self, inputs: &Matrix) -> Matrix;

    /// The inputs passed into this function are the outputs generated at this layer by the forward pass.
    /// The dvaulues are generated by the previous layer in the network.
    fn backward<'a>(&'a mut self, dvalues: &Matrix, inputs: &Matrix) -> Matrix;
}

#[cfg(test)]
mod tests {
    #[test]
    fn testflow() {

    }
}